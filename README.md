<img src="galeria_visual_readme/img/titulo_principal.png" width="2000">

<div align="center">

  <img src="galeria_visual_readme/experimento_001_video_002.gif" height="120" alt="experimento_001_video_002">
  <img src="galeria_visual_readme/experimento_001_video_003.gif" height="120" alt="experimento_001_video_003">

  <img src="galeria_visual_readme/experimento_002_video_001.gif" height="120" alt="experimento_002_video_001">
  <img src="galeria_visual_readme/experimento_002_video_003.gif" height="120" alt="experimento_002_video_003">

  <img src="galeria_visual_readme/experimento_003_video_001.gif" height="120" alt="experimento_003_video_001">
  <img src="galeria_visual_readme/experimento_003_video_002.gif" height="120" alt="experimento_003_video_002">

</div>

<div align="center">
  
[üìñ Contexto del estudio](#contexto-del-estudio) |
[üé• Galer√≠a de experimentos](#galer√≠a-de-experimentos) |
[üí° C√≥mo funciona](#c√≥mo-funciona) |
[üõ†Ô∏è Requisitos](#requisitos) |
[üêõ Reportar problemas](https://github.com/TU_USUARIO/TU_REPO/issues) |
[üìö Cr√©ditos y atribuciones](#cr√©ditos-y-atribuciones) |
[üì¨ Contacto](#contacto)

</div>

<div align="center">

  <a href="https://www.python.org/"><img src="https://img.shields.io/badge/Versi√≥n_de_Python-3.10.15-blue" alt="Python"></a>
  <a href="https://flask.palletsprojects.com/"><img src="https://img.shields.io/badge/Framework_Flask-3.0.3-lightgrey" alt="Flask"></a>
  <a href="https://deeplabcut.github.io/DeepLabCut/"><img src="https://img.shields.io/badge/Biblioteca_DeepLabCut-3.0.0rc4-yellowgreen" alt="DeepLabCut"></a>
  <a href="https://sleap.ai/"><img src="https://img.shields.io/badge/Software_SLEAP-1.3.3-ff69b4" alt="SLEAP"></a>
  <a href="https://numpy.org/"><img src="https://img.shields.io/badge/Librer√≠a_NumPy-1.26.4-lightblue" alt="NumPy"></a>
  <a href="https://pandas.pydata.org/"><img src="https://img.shields.io/badge/Librer√≠a_Pandas-2.2.3-darkgreen" alt="Pandas"></a>
  <a href="https://joblib.readthedocs.io/"><img src="https://img.shields.io/badge/Serializaci√≥n_con_Joblib-1.4.2-orange" alt="Joblib"></a>
  <a href="https://pyyaml.org/wiki/PyYAMLDocumentation"><img src="https://img.shields.io/badge/Manejo_de_PyYAML-6.0.2-brightyellow" alt="PyYAML"></a>
  <a href="https://werkzeug.palletsprojects.com/"><img src="https://img.shields.io/badge/Servidor_Werkzeug-3.0.4-blueviolet" alt="Werkzeug"></a>
  
  <a href="https://www.ibm.com/es-es/think/topics/k-nearest-neighbors"><img src="https://img.shields.io/badge/Modelo_KNN-blueviolet" alt="KNN"></a>
  <a href="https://www.ibm.com/mx-es/think/topics/random-forest"><img src="https://img.shields.io/badge/Modelo_Random_Forest-forestgreen" alt="Random Forest"></a>
  <a href="https://www.ibm.com/es-es/think/topics/decision-trees"><img src="https://img.shields.io/badge/Modelo_Decision_Tree-darkorange" alt="Decision Tree"></a>
  <a href="https://www.ibm.com/mx-es/think/topics/logistic-regression"><img src="https://img.shields.io/badge/Modelo_Regresi√≥n_Log√≠stica-crimson" alt="Regresi√≥n Log√≠stica"></a>
  <a href="https://www.ibm.com/mx-es/think/topics/support-vector-machines"><img src="https://img.shields.io/badge/Modelo_SVM-darkslateblue" alt="SVM"></a>
  <a href="https://www.ibm.com/mx-es/think/topics/naive-bayes"><img src="https://img.shields.io/badge/Modelo_Naive_Bayes-goldenrod" alt="Naive Bayes"></a>

  <a href="https://www.pexels.com/video/close-up-view-of-a-cute-black-and-tan-short-coated-dog-7682696/"><img src="https://img.shields.io/badge/Video_de_referencia-Pexels_KoolShooters-9cf" alt="Video de Pexels"></a>

</div>

# ¬°Bienvenido! üëã

**[PoseDoggo](https://github.com/galaxiahfast/WebAppDLC/blob/main/README.md)** es una aplicaci√≥n web no oficial desarrollada en framework Flask que utiliza las funciones del software **[DeepLabCut‚Ñ¢Ô∏è](https://deeplabcut.github.io/DeepLabCut/README.html)** en Python e incorpora [aprendizaje autom√°tico](https://www.ibm.com/mx-es/think/topics/machine-learning) y [aprendizaje profundo](https://www.ibm.com/es-es/think/topics/deep-learning) para realizar an√°lisis autom√°tico enfoc√°ndose en clasificar tres posturas corporales distintas (acostado, parado y erguido sobre las patas traseras) en perros mediante un entrenamiento para un solo animal, a trav√©s del procesamiento de videos de las razas **Setter Ingl√©s**, **Chihuahua** y **Jack Russell Terrier** en entornos espec√≠ficos.

[Lee m√°s sobre el proyecto oficial de DeepLabCut aqu√≠](https://github.com/DeepLabCut/DeepLabCut)

# Contexto del estudio

**[PoseDoggo](https://github.com/galaxiahfast/WebAppDLC/blob/main/README.md)** fue desarrollada como caso de estudio dentro de una tesis de licenciatura con el objetivo de demostrar c√≥mo se puede lograr una integraci√≥n funcional de programaci√≥n orientada al **[aprendizaje autom√°tico](https://www.ibm.com/mx-es/think/topics/machine-learning)** y **[aprendizaje profundo](https://www.ibm.com/es-es/think/topics/deep-learning)** cuando se aplican al an√°lisis de aspectos complejos de los comportamientos de perros, especialmente aquellos patrones de conducta que resultan dif√≠ciles de estudiar o que no podr√≠an investigarse de manera efectiva mediante el uso de m√©todos cuantitativos tradicionales o enfoques experimentales convencionales en el campo de la **[etolog√≠a](https://www.menteyciencia.com/etologia-que-es-y-cual-es-su-objeto-de-estudio/)** canina contempor√°nea.

Como parte del proceso de **[PoseDoggo](https://github.com/galaxiahfast/WebAppDLC/blob/main/README.md)**, se realiz√≥ un an√°lisis comparativo entre las herramientas de software libre **[SLEAP (Social LEAP Estimates Animal Poses)‚Ñ¢Ô∏è](https://sleap.ai/)** y **[DeepLabCut (DLC)‚Ñ¢Ô∏è](https://deeplabcut.github.io/DeepLabCut/README.html)** con el objetivo de identificar la alternativa m√°s adecuada para implementar la detecci√≥n de posturas en los perros definidos para los tres experimentos descritos anteriormente. Los criterios de evaluaci√≥n incluyeron los requerimientos de poder de c√≥mputo, las necesidades de memoria para la ejecuci√≥n en GPU, la facilidad de uso del sistema y la disponibilidad de documentaci√≥n t√©cnica, lo que condujo a la selecci√≥n de **[DeepLabCut‚Ñ¢Ô∏è](https://deeplabcut.github.io/DeepLabCut/README.html)**. Es importante aclarar que esto no implica que una herramienta sea mejor que otra, sino que, para esta investigaci√≥n espec√≠fica, **[DLC‚Ñ¢Ô∏è](https://deeplabcut.github.io/DeepLabCut/README.html)** result√≥ m√°s adecuado.

A partir de esta selecci√≥n surgi√≥ la idea del caso de estudio para el desarrollo del an√°lisis de poses en estos tres experimentos de manera autom√°tica, creando una interfaz web intuitiva que, mediante modificaciones en el c√≥digo de la aplicaci√≥n, permitiera a los investigadores procesar y analizar videos de comportamiento canino sin requerir conocimientos avanzados de programaci√≥n o configuraciones complejas de software especializado.

[Lee m√°s sobre el proyecto oficial de SLEAP aqu√≠](https://sleap.ai/)




















# Cr√©ditos y atribuciones

Este proyecto usa tecnolog√≠as, materiales acad√©micos y recursos visuales que no son nuestros, entonces para respetar el trabajo de otros se citan los art√≠culos originales que explican c√≥mo funcionan **[DeepLabCut‚Ñ¢Ô∏è](https://deeplabcut.github.io/DeepLabCut/README.html)** (licencia GNU LGPL v3.0, uso acad√©mico con citaci√≥n requerida) y **[SLEAP‚Ñ¢Ô∏è](https://sleap.ai/)** (licencia Clear BSD, solo uso acad√©mico/investigaci√≥n), que son la base de esta aplicaci√≥n web para analizar posturas de perros. Tambi√©n se incluyen [videos de perros](https://www.pexels.com/video/close-up-view-of-a-cute-black-and-tan-short-coated-dog-7682696/) en alta resoluci√≥n del autor [KoolShooters](https://www.pexels.com/@koolshooters/) disponibles gratis en Pexels (uso gratuito sin restricciones), junto con materiales educativos de IBM sobre [aprendizaje autom√°tico](https://www.ibm.com/mx-es/think/topics/machine-learning) y [aprendizaje profundo](https://www.ibm.com/es-es/think/topics/deep-learning) (sujetos a restricciones del contrato GSA ADP Schedule de IBM), recursos que ayudan a entender mejor estas tecnolog√≠as para cualquier persona que est√© interesada en el tema.

## Citaciones relevantes

```bibtex
@article{Mathisetal2018,
    title = {DeepLabCut: markerless pose estimation of user-defined body parts with deep learning},
    author = {Alexander Mathis and Pranav Mamidanna and Kevin M. Cury and Taiga Abe  and Venkatesh N. Murthy and Mackenzie W. Mathis and Matthias Bethge},
    journal = {Nature Neuroscience},
    year = {2018},
    url = {https://www.nature.com/articles/s41593-018-0209-y}}

@article{NathMathisetal2019,
    title = {Using DeepLabCut for 3D markerless pose estimation across species and behaviors},
    author = {Nath*, Tanmay and Mathis*, Alexander and Chen, An Chi and Patel, Amir and Bethge, Matthias and Mathis, Mackenzie W},
    journal = {Nature Protocols},
    year = {2019},
    url = {https://doi.org/10.1038/s41596-019-0176-0}}

@InProceedings{Mathis_2021_WACV,
    author = {Mathis, Alexander and Biasi, Thomas and Schneider, Steffen and Yuksekgonul, Mert and Rogers, Byron and Bethge, Matthias and Mathis, Mackenzie W.},
    title = {Pretraining Boosts Out-of-Domain Robustness for Pose Estimation},
    booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
    month = {January},
    year = {2021},
    pages = {1859-1868}}

@article{Lauer2022MultianimalPE,
    title = {Multi-animal pose estimation, identification and tracking with DeepLabCut},
    author = {Jessy Lauer and Mu Zhou and Shaokai Ye and William Menegas and Steffen Schneider and Tanmay Nath and Mohammed Mostafizur Rahman and Valentina Di Santo and Daniel Soberanes and Guoping Feng and Venkatesh N. Murthy and George Lauder and Catherine Dulac and M. Mathis and Alexander Mathis},
    journal = {Nature Methods},
    year = {2022},
    volume = {19},
    pages = {496 - 504}}

@article{Ye2024SuperAnimal,
    title = {SuperAnimal pretrained pose estimation models for behavioral analysis},
    author = {Shaokai Ye and Anastasiia Filippova and Jessy Lauer and Steffen Schneider and Maxime Vidal and and Tian Qiu and Alexander Mathis and Mackenzie W. Mathis},
    journal = {Nature Communications},
    year = {2024},
    volume = {15}}

@article{Mathis2020DeepLT,
    title = {Deep learning tools for the measurement of animal behavior in neuroscience},
    author = {Mackenzie W. Mathis and Alexander Mathis},
    journal = {Current Opinion in Neurobiology},
    year = {2020},
    volume = {60},
    pages = {1-11}}

@article{Mathis2020Primer,
    title = {A Primer on Motion Capture with Deep Learning: Principles, Pitfalls, and Perspectives},
    author = {Alexander Mathis and Steffen Schneider and Jessy Lauer and Mackenzie W. Mathis},
    journal = {Neuron},
    year = {2020},
    volume = {108},
    pages = {44-65}}

@article{MathisWarren2018speed,
    author = {Mathis, Alexander and Warren, Richard A.},
    title = {On the inference speed and video-compression robustness of DeepLabCut},
    year = {2018},
    doi = {10.1101/457242},
    publisher = {Cold Spring Harbor Laboratory},
    URL = {https://www.biorxiv.org/content/early/2018/10/30/457242},
    eprint = {https://www.biorxiv.org/content/early/2018/10/30/457242.full.pdf},
    journal = {bioRxiv}}

@article{Pereira2022sleap,
    title = {SLEAP: A deep learning system for multi-animal pose tracking},
    author = {Pereira, Talmo D and Tabris, Nathaniel and Matsliah, Arie and Turner, David M and Li, Junyu and Ravindranath, Shruthi and Papadoyannis, Eleni S and Normand, Edna and Deutsch, David S and Wang, Z. Yan and McKenzie-Smith, Grace C and Mitelut, Catalin C and Castro, Marielisa Diez and D'Uva, John and Kislin, Mikhail and Sanes, Dan H and Kocher, Sarah D and Samuel S-H and Falkner, Annegret L and Shaevitz, Joshua W and Murthy, Mala},
    journal = {Nature Methods},
    volume = {19},
    number = {4},
    year = {2022},
    publisher = {Nature Publishing Group}}
